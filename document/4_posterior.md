Posterior Corrections for Human Bias
=====================================

While working to normalize contributing users' contexts is possible in well-controlled circumstances, there are cases where either 
 the data is already collected, or 
 where there is a limit to the amount of control a system designer can exert over contributors.

In the second of two research chapters, the proposed dissertation will look at methods to normalize for bias in already-collected metadata.
This will integrate previously-completed research \cite{}<!--TODO ASIS&T--> on improving signal in information retrieval relevance judgment and perform new work on normalizing quality judgments in volunteer crowdsourcing.
Since 


## Scope

The assumptions and focus of this chapter will stay unchanged,
 pursuing the assumption of honest-but-biased workers, and
 focusing on crowdsourcing additional metadata for improved information retrieval indexing.

## Problem

## Existing Work

Much work has been completed in posterior corrections for paid crowdsourcing contributions.


The research covered in this


## Methodology

$P(r_s|C)\approx(1-\lambda)(P(r)+\lambda P(r|R)$ <!--_-->
Where, 
$P(r|R)=\sum_{i=1}^{n}{P(r|t_i}$

### Evaluation

### Baseline

